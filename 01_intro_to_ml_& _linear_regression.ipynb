{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Session 1 (January 24, 2025)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Brief Introduction to Machine Learning\n",
    "\n",
    "Machine learning can be categorized into three types: unsupervised, supervised, and reinforcement learning. \n",
    "\n",
    "Unsupervised learning usually deals with unlabeled data in order to detect pattents and data characterization. Clustering is under unsupervised learning and it also covers dimensionality reduction.\n",
    "\n",
    "Supervised learning uses labeled data for prediction and classification. Some examples of supervised learning is regression and classification.\n",
    "\n",
    "A third category of machine learning is reinforcement learning. It mimics the trial-and-error learning process that humans use to achieve their goals.\n",
    "\n",
    "In this course, we'll discuss the following:\n",
    "\n",
    "-- Machine Learning Pipelines: data collection and data engineering, machine learning implementation (our main focus), evaluations, and reports.\n",
    "\n",
    "-- Bias-Variance Trade-off: bias (accuracy), variance (precision: getting consistent results). This part deals with sensitivity todatasets and model configurations.\n",
    "\n",
    "-- Overfitting: Train (parameter estimation)/Validation (hyperparameter tuning)/Test (evaluation) Split. We usually follow the 80-20 train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall: Regression\n",
    "\n",
    "$y = Xw $ \n",
    "\n",
    "$\\implies w = (X^T X)^{-1} X^Ty$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([1, 2, 3, 4, 5]) #independent var\n",
    "y = np.array([4, 7, 10, 13, 16]) #dependent var\n",
    "\n",
    "\n",
    "XD = np.c_[np.ones(X.shape[0]),X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 2.],\n",
       "       [1., 3.],\n",
       "       [1., 4.],\n",
       "       [1., 5.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 3.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_best = np.linalg.inv(XD.T.dot(XD)).dot(XD.T).dot(y)\n",
    "w_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that 1 is the intercept while 3 is the slope. For our next example, we will create a singular matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  2.],\n",
       "       [ 1.,  2.,  4.],\n",
       "       [ 1.,  3.,  6.],\n",
       "       [ 1.,  4.,  8.],\n",
       "       [ 1.,  5., 10.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1 = np.array([1, 2, 3, 4, 5])\n",
    "X_2 = 2 * X_1\n",
    "\n",
    "XD = np.c_[np.ones(X.shape[0]),X_1, X_2]\n",
    "XD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-7fe5b76c6acf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mw_best\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mw_best\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[0msignature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'D->D'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'd->d'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m     \u001b[0mainv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Singular matrix\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "w_best = np.linalg.inv(XD.T.dot(XD)).dot(XD.T).dot(y)\n",
    "w_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can we do in this case? If $X^{T}X$ is singular, we use the pseudoinverse (Moore-Penrose Inverse).\n",
    "\n",
    "Consider the system of linear equations:\n",
    "$A\\vec{x} = \\vec{b}$.\n",
    "\n",
    "Ideally, $A$ is nonsingular and thus, $\\vec{x} = A^{-1}\\vec{b}$.\n",
    "\n",
    "If $A$ is singular, we want to minimize $|| A\\vec{x} - \\vec{b}||_{2}$. That is, we want to find $A^{+}$ s.t. $|| A\\vec{x} - \\vec{b}||_{2} \\geq || A\\vec{x} - \\vec{b}||_{2}$ where $\\vec{z} = A^{+}\\vec{b}$ \n",
    "\n",
    "if $A$ is nonsingular, then $A^{+} = A^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Singular matrix, pseudoinverse used\n"
     ]
    }
   ],
   "source": [
    "X_1 = np.array([1, 2, 3, 4, 5])\n",
    "X_2 = 2 * X_1\n",
    "\n",
    "XD = np.c_[np.ones(X.shape[0]),X_1, X_2]\n",
    "\n",
    "try: \n",
    "    w_best = np.linalg.inv(XD.T.dot(XD)).dot(XD.T).dot(y)\n",
    "except np.linalg.LinAlgError as e:\n",
    "    print('Warning: Singular matrix, pseudoinverse used')\n",
    "    w_best = np.linalg.pinv(XD.T.dot(XD)).dot(XD.T).dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 0.6, 1.2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `sk_learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([1, 2, 3, 4, 5]) #independent var\n",
    "y = np.array([4, 7, 10, 13, 16]) #dependent var\n",
    "\n",
    "#Step 1: Initialize the linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "#Step 2: Fit the model to data. For sklearn, X is required to be 2-dimensional.\n",
    "X = np.array([1, 2, 3, 4, 5]).reshape(-1,1) #reshaping X\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_decision_function',\n",
       " '_estimator_type',\n",
       " '_get_param_names',\n",
       " '_preprocess_data',\n",
       " '_residues',\n",
       " '_set_intercept',\n",
       " 'coef_',\n",
       " 'copy_X',\n",
       " 'fit',\n",
       " 'fit_intercept',\n",
       " 'get_params',\n",
       " 'intercept_',\n",
       " 'n_jobs',\n",
       " 'normalize',\n",
       " 'predict',\n",
       " 'rank_',\n",
       " 'score',\n",
       " 'set_params',\n",
       " 'singular_']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model) #A way to access the model's attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope: 3.000000000000001\n",
      "Intercept: 0.9999999999999964\n"
     ]
    }
   ],
   "source": [
    "w_best = model.coef_\n",
    "intercept = model.intercept_\n",
    "print(f\"Slope: {w_best[0]}\")\n",
    "print(f\"Intercept: {intercept}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1 = np.array([1, 2, 3, 4, 5])\n",
    "X_2 = 2 * X_1\n",
    "\n",
    "XD = np.c_[X_1, X_2]\n",
    "\n",
    "model.fit(XD,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope: [0.6 1.2]\n",
      "Intercept: 1.0\n"
     ]
    }
   ],
   "source": [
    "w_best = model.coef_\n",
    "intercept = model.intercept_\n",
    "print(f\"Slope: {w_best}\") # this refers to w_1 and w_2\n",
    "print(f\"Intercept: {intercept}\") # this is w_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$R^2$ is the cofficient of determination. \n",
    "\n",
    "$\\implies R^2 = 1- \\frac{SS_{R}}{SS_{T}}$\n",
    "\n",
    "where $SS_{R}$ is the sum of squares of the residuals and $SS_{T}$ is the total sum of squares.\n",
    "\n",
    "$\\implies 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y}_i)^2}$\n",
    "\n",
    "where $\\bar{y} = \\frac{1}{n} \\sum_{i=1}^{n} y_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.76405235,  3.40015721,  6.97873798, 11.2408932 , 13.86755799,\n",
       "       14.02272212, 18.95008842, 20.84864279, 23.89678115, 27.4105985 ])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0) #Set seed for reproducability\n",
    "\n",
    "# Data\n",
    "\n",
    "X = np.array(list(range(1, 11))).reshape(-1, 1)\n",
    "y = np.array([3 * n for n in range(10)]) + np.random.normal(0, 1, 10)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope: 2.8369468245195097\n",
      "Intercept: -1.3105001099203442\n"
     ]
    }
   ],
   "source": [
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "w_best = model.coef_\n",
    "intercept = model.intercept_\n",
    "print(f\"Slope: {w_best[0]}\")\n",
    "print(f\"Intercept: {intercept}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Values: [ 6.97873798 23.89678115]\n",
      "Predicted Values: [ 7.20034036 24.22202131]\n",
      "R2: 0.9989176949332313\n"
     ]
    }
   ],
   "source": [
    "#Testing\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Actual Values: {y_test}\") \n",
    "print(f\"Predicted Values: {y_pred}\")\n",
    "print(f\"R2: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise for next programming session: Try to create an implementation of Gradient Descent from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "$w \\leftarrow w_o - \\eta \\frac{\\partial{L}}{\\partial{w}}$\n",
    "\n",
    "where $L$ is the loss function.\n",
    "\n",
    "Steps for implementaion:\n",
    "\n",
    "-- Initiate weights\n",
    "\n",
    "-- Compute for gradient\n",
    "\n",
    "-- Adjust the weights\n",
    "\n",
    "-- Repeat steps 2 and 3 until a stopping criterian is met"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
